{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# π Estimation with Monte Carlo methods\n",
    "We demonstrate how to run Monte Carlo simulations with lithops over IBM Cloud Functions. This notebook contains an example of estimation the number π with Monte Carlo. The goal of this notebook is to demonstrate how IBM Cloud Functions can benefit Monte Carlo simulations and not how it can be done using lithops.<br>\n",
    "A Monte Carlo algorithm would randomly place points in the square and use the percentage of randomized points inside of the circle to estimate the value of π\n",
    "![pi](https://upload.wikimedia.org/wikipedia/commons/8/84/Pi_30K.gif)\n",
    "Requirements to run this notebook:\n",
    "\n",
    "* AWS Cloud or GCP account. \n",
    "* You will need to have at least one existing object storage bucket. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Install dependencies\n",
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from random import random\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import lithops\n",
    "except:\n",
    "    %pip install -r requirements.txt\n",
    "    import lithops\n",
    "\n",
    "# you can modify logging level if needed\n",
    "#logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Write Python code that implements Monte Carlo simulation \n",
    "Below is an example of Python code to demonstrate Monte Carlo model for estimate PI\n",
    "\n",
    "'EstimatePI' is a Python class that we use to represent a single PI estimation. You may configure the following parameters:\n",
    "\n",
    "MAP_INSTANCES - number of cloud functions invocations. Default is 100<br>\n",
    "randomize_per_map - number of points to random in a single invocation. Default is 10,000,000\n",
    "\n",
    "Our code contains two major Python methods:\n",
    "\n",
    "def randomize_points(self,data=None) - a function to random number of points and return the percentage of points\n",
    "    that inside the circle<br>\n",
    "def process_in_circle_points(self, results, futures): - summarize results of all randomize_points\n",
    "  executions (aka \"reduce\" in map-reduce paradigm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_INSTANCES = 50\n",
    "\n",
    "\n",
    "class EstimatePI:\n",
    "    randomize_per_map = 10000000\n",
    "\n",
    "    def __init__(self):\n",
    "        self.total_randomize_points = MAP_INSTANCES * self.randomize_per_map\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Total Randomize Points: {:,}\".format(self.randomize_per_map * MAP_INSTANCES)\n",
    "\n",
    "    @staticmethod\n",
    "    def predicate():\n",
    "        x = random()\n",
    "        y = random()\n",
    "        return (x ** 2) + (y ** 2) <= 1\n",
    "\n",
    "    def randomize_points(self, data):\n",
    "        in_circle = 0\n",
    "        for _ in range(self.randomize_per_map):\n",
    "            in_circle += self.predicate()\n",
    "        return float(in_circle / self.randomize_per_map)\n",
    "\n",
    "    def process_in_circle_points(self, results):\n",
    "        in_circle_percent = 0\n",
    "        for map_result in results:\n",
    "            in_circle_percent += map_result\n",
    "        estimate_PI = float(4 * (in_circle_percent / MAP_INSTANCES))\n",
    "        return estimate_PI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Configure access to your Cloud Storage and Cloud Functions\n",
    "\n",
    "Configure access details to your AWS or other cloud provider.  'storage_bucket'  should point to some pre-existing bucket. This bucket will be used by Lithops to store intermediate results. All results will be stored in the folder `lithops.jobs`.\n",
    "\n",
    "e.g. for GCP your `.lithops_config` should be similar to: \n",
    "    \n",
    "    lithops:\n",
    "        storage: gcp_storage\n",
    "        backend: gcp_functions\n",
    "        bucket: lithops-pipelines\n",
    "    \n",
    "    gcp:\n",
    "        credentials_path : <PATH_TO_JSON_KEYS>\n",
    "        region : <GCP_REGION>\n",
    "    \n",
    "    gcp_functions:\n",
    "        region : <GCP_REGION>\n",
    "    \n",
    "    gcp_storage:\n",
    "        region: <GCP_REGION>\n",
    "        storage_bucket: <GCP_STORAGE_BUCKET>\n",
    "\n",
    "For AWS your `.lithops_config` should be similar to: \n",
    "    \n",
    "    lithops:\n",
    "        storage: aws_s3\n",
    "        backend: aws_lambda\n",
    "    \n",
    "    aws:\n",
    "        access_key_id : <AWS_ACCESS_KEY_ID>\n",
    "        secret_access_key : <AWS_SECRET_ACCESS_KEY> \n",
    "        \n",
    "    aws_s3:\n",
    "        storage_bucket: <S3_BUCKET>\n",
    "        region_name : <REGION>\n",
    "    \n",
    "    aws_lambda:\n",
    "        execution_role: <AWS_ROLE_ARN>\n",
    "        region_name: <REGION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Execute simulation with Lithops over IBM Cloud Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 10:34:41,216 [INFO] config.py:139 -- Lithops v3.6.1.dev0 - Python3.12\n",
      "2025-03-21 10:34:41,216 [INFO] localhost.py:39 -- Localhost storage client created\n",
      "2025-03-21 10:34:41,217 [INFO] localhost.py:78 -- Localhost compute v2 client created\n",
      "2025-03-21 10:34:41,227 [INFO] invokers.py:119 -- ExecutorID 380724-8 | JobID M000 - Selected Runtime: python - 2048MB\n",
      "2025-03-21 10:34:41,232 [INFO] invokers.py:186 -- ExecutorID 380724-8 | JobID M000 - Starting function invocation: randomize_points() - Total: 50 activations\n",
      "2025-03-21 10:34:41,253 [INFO] invokers.py:225 -- ExecutorID 380724-8 | JobID M000 - View execution logs at /tmp/lithops-bigrobbin/logs/380724-8-M000.log\n",
      "2025-03-21 10:34:41,258 [INFO] wait.py:105 -- ExecutorID 380724-8 - Waiting for 20% of 50 function activations to complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo simulation for estimating PI spawing over 50 Cloud Function invocations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b5b21e87b84758928c7d770a2f415b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 10:34:44,517 [INFO] invokers.py:119 -- ExecutorID 380724-8 | JobID R000 - Selected Runtime: python - 2048MB\n",
      "2025-03-21 10:34:44,522 [INFO] invokers.py:186 -- ExecutorID 380724-8 | JobID R000 - Starting function invocation: process_in_circle_points() - Total: 1 activations\n",
      "2025-03-21 10:34:44,523 [INFO] invokers.py:225 -- ExecutorID 380724-8 | JobID R000 - View execution logs at /tmp/lithops-bigrobbin/logs/380724-8-R000.log\n",
      "2025-03-21 10:34:44,523 [INFO] executors.py:494 -- ExecutorID 380724-8 - Getting results from 1 function activations\n",
      "2025-03-21 10:34:44,523 [INFO] wait.py:101 -- ExecutorID 380724-8 - Waiting for 41 function activations to complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6634168c3e3d43e9b57fb5e39d2f88d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/41  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 10:34:48,233 [INFO] executors.py:618 -- ExecutorID 380724-8 - Cleaning temporary data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Randomize Points: 500,000,000\n",
      "Estimation of Pi:  3.1424403999999986\n",
      "\n",
      "Completed in: 7.019773960113525 seconds\n"
     ]
    }
   ],
   "source": [
    "iterdata = [0] * MAP_INSTANCES # funcion + iterable --> length ( numero de elementos )\n",
    "est_pi = EstimatePI()\n",
    "\n",
    "start_time = time()\n",
    "print(\"Monte Carlo simulation for estimating PI spawing over {} Cloud Function invocations\".format(MAP_INSTANCES))\n",
    "# obtain lithops executor\n",
    "pw = lithops.FunctionExecutor(runtime_memory=2048)\n",
    "\n",
    "# execute the code\n",
    "pw.map_reduce(est_pi.randomize_points, iterdata, est_pi.process_in_circle_points) # iterdata : \n",
    "#get results\n",
    "result = pw.get_result()\n",
    "elapsed = time()\n",
    "print(str(est_pi))\n",
    "print(\"Estimation of Pi: \", result)\n",
    "print(\"\\nCompleted in: \" + str(elapsed - start_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure of worker_func_perf_energy: {'pkg': 609.52, 'cores': 590.26, 'total': 1199.78}\n",
      "Using key 'pkg' from worker_func_perf_energy dictionary\n",
      "Perf Energy: 560.6576470588235\n",
      "Experiment total price is 0.00061 USD\n"
     ]
    }
   ],
   "source": [
    "# Price in AWS\n",
    "import numpy as np\n",
    "\n",
    "stats = [f.stats for f in pw.futures]\n",
    "mean_exec_time = np.mean([stat['worker_func_exec_time'] for stat in stats])\n",
    "\n",
    "# Debug: Print the structure of worker_func_perf_energy to understand what's in it\n",
    "if stats and 'worker_func_perf_energy' in stats[0]:\n",
    "    print(f\"Structure of worker_func_perf_energy: {stats[0]['worker_func_perf_energy']}\")\n",
    "\n",
    "# Handle worker_func_perf_energy as a dictionary\n",
    "# If it's a dictionary, we need to extract a specific value or calculate an aggregate\n",
    "try:\n",
    "    # Option 1: If there's a specific key we want to extract from each dictionary\n",
    "    # For example, if each dictionary has a 'total' or 'value' key\n",
    "    if stats and 'worker_func_perf_energy' in stats[0] and isinstance(stats[0]['worker_func_perf_energy'], dict):\n",
    "        # Try to find a numeric key in the dictionary\n",
    "        sample_dict = stats[0]['worker_func_perf_energy']\n",
    "        numeric_keys = [k for k, v in sample_dict.items() if isinstance(v, (int, float))]\n",
    "        \n",
    "        if numeric_keys:\n",
    "            # Use the first numeric key found\n",
    "            key_to_use = numeric_keys[0]\n",
    "            worker_func_perf_energy = np.mean([stat['worker_func_perf_energy'][key_to_use] \n",
    "                                              for stat in stats \n",
    "                                              if 'worker_func_perf_energy' in stat \n",
    "                                              and key_to_use in stat['worker_func_perf_energy']])\n",
    "            print(f\"Using key '{key_to_use}' from worker_func_perf_energy dictionary\")\n",
    "        else:\n",
    "            # If no numeric keys found, skip this calculation\n",
    "            worker_func_perf_energy = \"N/A (No numeric values found in dictionary)\"\n",
    "    else:\n",
    "        # If it's not a dictionary or doesn't exist, skip this calculation\n",
    "        worker_func_perf_energy = \"N/A\"\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error processing worker_func_perf_energy: {e}\")\n",
    "    worker_func_perf_energy = \"N/A (Error)\"\n",
    "\n",
    "print(f\"Perf Energy: {worker_func_perf_energy}\")\n",
    "# print(f\"Global Perf Energy: {pw.stats.get('worker_func_perf_energy', 'N/A')}\")\n",
    "\n",
    "gbxms_price = 0.0000000167\n",
    "sum_total_time = sum([stat['worker_exec_time'] for stat in stats]) * 1000\n",
    "price = gbxms_price * sum_total_time * 0.256  # Price GB/ms * sum of times in ms * 0.256 GB runtime\n",
    "\n",
    "print(f'Experiment total price is {round(price, 5)} USD')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
